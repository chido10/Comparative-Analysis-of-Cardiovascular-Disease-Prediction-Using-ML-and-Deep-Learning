{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb908653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "587/587 [==============================] - 2s 2ms/step - loss: 253.4826 - accuracy: 0.6205 - val_loss: 132.2225 - val_accuracy: 0.7501\n",
      "Epoch 2/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 135.4621 - accuracy: 0.6219 - val_loss: 143.6549 - val_accuracy: 0.2520\n",
      "Epoch 3/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 120.3456 - accuracy: 0.6216 - val_loss: 63.4173 - val_accuracy: 0.7501\n",
      "Epoch 4/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 110.8086 - accuracy: 0.6249 - val_loss: 59.8313 - val_accuracy: 0.7501\n",
      "Epoch 5/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 84.6855 - accuracy: 0.6334 - val_loss: 144.7440 - val_accuracy: 0.7501\n",
      "Epoch 6/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 96.7965 - accuracy: 0.6306 - val_loss: 193.5664 - val_accuracy: 0.7501\n",
      "Epoch 7/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 72.6976 - accuracy: 0.6364 - val_loss: 57.1597 - val_accuracy: 0.7501\n",
      "Epoch 8/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 73.4996 - accuracy: 0.6332 - val_loss: 92.6049 - val_accuracy: 0.3010\n",
      "Epoch 9/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 59.2914 - accuracy: 0.6349 - val_loss: 38.6441 - val_accuracy: 0.7501\n",
      "Epoch 10/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 51.0169 - accuracy: 0.6364 - val_loss: 8.6638 - val_accuracy: 0.7495\n",
      "Epoch 11/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 61.4805 - accuracy: 0.6357 - val_loss: 40.0122 - val_accuracy: 0.7501\n",
      "Epoch 12/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 56.6479 - accuracy: 0.6410 - val_loss: 74.4461 - val_accuracy: 0.7501\n",
      "Epoch 13/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 34.1163 - accuracy: 0.6442 - val_loss: 29.9383 - val_accuracy: 0.2661\n",
      "Epoch 14/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 51.3112 - accuracy: 0.6354 - val_loss: 11.9904 - val_accuracy: 0.4472\n",
      "Epoch 15/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 39.9957 - accuracy: 0.6423 - val_loss: 24.1012 - val_accuracy: 0.3611\n",
      "Epoch 16/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 36.7458 - accuracy: 0.6428 - val_loss: 47.3714 - val_accuracy: 0.7501\n",
      "Epoch 17/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 33.4156 - accuracy: 0.6475 - val_loss: 14.6718 - val_accuracy: 0.7499\n",
      "Epoch 18/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 31.4459 - accuracy: 0.6507 - val_loss: 78.3226 - val_accuracy: 0.2514\n",
      "Epoch 19/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 33.2898 - accuracy: 0.6552 - val_loss: 3.8651 - val_accuracy: 0.6498\n",
      "Epoch 20/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 29.8959 - accuracy: 0.6466 - val_loss: 4.3122 - val_accuracy: 0.7405\n",
      "Epoch 21/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 25.1535 - accuracy: 0.6484 - val_loss: 20.7574 - val_accuracy: 0.3245\n",
      "Epoch 22/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 17.1540 - accuracy: 0.6647 - val_loss: 12.3316 - val_accuracy: 0.7499\n",
      "Epoch 23/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 18.8844 - accuracy: 0.6651 - val_loss: 10.9566 - val_accuracy: 0.4372\n",
      "Epoch 24/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 19.7462 - accuracy: 0.6711 - val_loss: 4.7396 - val_accuracy: 0.6170\n",
      "Epoch 25/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 13.4826 - accuracy: 0.6822 - val_loss: 21.0667 - val_accuracy: 0.2970\n",
      "Epoch 26/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 19.6787 - accuracy: 0.6657 - val_loss: 30.0465 - val_accuracy: 0.3453\n",
      "Epoch 27/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 12.1797 - accuracy: 0.6783 - val_loss: 11.3336 - val_accuracy: 0.3960\n",
      "Epoch 28/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 15.6229 - accuracy: 0.6718 - val_loss: 11.1486 - val_accuracy: 0.7501\n",
      "Epoch 29/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 13.7180 - accuracy: 0.6740 - val_loss: 1.8563 - val_accuracy: 0.7848\n",
      "Epoch 30/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 15.4823 - accuracy: 0.6681 - val_loss: 3.2481 - val_accuracy: 0.6847\n",
      "Epoch 31/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 11.0341 - accuracy: 0.6849 - val_loss: 5.0527 - val_accuracy: 0.7060\n",
      "Epoch 32/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 8.1266 - accuracy: 0.6973 - val_loss: 9.2089 - val_accuracy: 0.7499\n",
      "Epoch 33/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 7.4801 - accuracy: 0.6967 - val_loss: 9.6364 - val_accuracy: 0.7548\n",
      "Epoch 34/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 9.0886 - accuracy: 0.6949 - val_loss: 1.1535 - val_accuracy: 0.8289\n",
      "Epoch 35/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 6.3696 - accuracy: 0.6968 - val_loss: 7.4243 - val_accuracy: 0.7501\n",
      "Epoch 36/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 8.6592 - accuracy: 0.6921 - val_loss: 1.6315 - val_accuracy: 0.8289\n",
      "Epoch 37/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 5.4383 - accuracy: 0.7020 - val_loss: 3.3872 - val_accuracy: 0.7635\n",
      "Epoch 38/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 4.8933 - accuracy: 0.7094 - val_loss: 1.1707 - val_accuracy: 0.7902\n",
      "Epoch 39/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 6.5777 - accuracy: 0.6989 - val_loss: 2.8633 - val_accuracy: 0.7469\n",
      "Epoch 40/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 6.8665 - accuracy: 0.6907 - val_loss: 4.4523 - val_accuracy: 0.5356\n",
      "Epoch 41/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 4.8972 - accuracy: 0.7122 - val_loss: 10.5817 - val_accuracy: 0.3911\n",
      "Epoch 42/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 3.1017 - accuracy: 0.7294 - val_loss: 4.9769 - val_accuracy: 0.7501\n",
      "Epoch 43/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 3.4314 - accuracy: 0.7254 - val_loss: 0.7239 - val_accuracy: 0.8517\n",
      "Epoch 44/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 5.1590 - accuracy: 0.7080 - val_loss: 1.7968 - val_accuracy: 0.7409\n",
      "Epoch 45/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 4.0422 - accuracy: 0.7210 - val_loss: 1.9216 - val_accuracy: 0.7322\n",
      "Epoch 46/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 3.6230 - accuracy: 0.7322 - val_loss: 7.7691 - val_accuracy: 0.7501\n",
      "Epoch 47/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 2.8964 - accuracy: 0.7242 - val_loss: 3.0222 - val_accuracy: 0.7461\n",
      "Epoch 48/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 3.0763 - accuracy: 0.7249 - val_loss: 6.4576 - val_accuracy: 0.4171\n",
      "Epoch 49/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 2.8626 - accuracy: 0.7370 - val_loss: 2.1256 - val_accuracy: 0.6821\n",
      "Epoch 50/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 4.8900 - accuracy: 0.7056 - val_loss: 2.4643 - val_accuracy: 0.7620\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 2.4643 - accuracy: 0.7620\n",
      "Test accuracy: 0.7620366215705872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = data.sample(frac=0.8, random_state=0)\n",
    "val_data = data.drop(train_data.index)\n",
    "\n",
    "# Preprocess the data\n",
    "train_labels = train_data.pop('Label')\n",
    "val_labels = val_data.pop('Label')\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(len(train_data.columns),)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels, epochs=50,\n",
    "                    validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(val_data, val_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d6d614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Using cached tensorflow_intel-2.12.0-cp311-cp311-win_amd64.whl (272.9 MB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (66.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: tensorflow-intel, tensorflow\n",
      "Successfully installed tensorflow-2.12.0 tensorflow-intel-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a53b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "587/587 [==============================] - 2s 2ms/step - loss: 6531963.0000 - mean_squared_error: 6531963.0000 - val_loss: 3272.8848 - val_mean_squared_error: 3272.8848\n",
      "Epoch 2/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 858553024.0000 - mean_squared_error: 858553024.0000 - val_loss: 13956.1729 - val_mean_squared_error: 13956.1729\n",
      "Epoch 3/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 295472160.0000 - mean_squared_error: 295472160.0000 - val_loss: 12076.4219 - val_mean_squared_error: 12076.4219\n",
      "Epoch 4/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 172473040.0000 - mean_squared_error: 172473040.0000 - val_loss: 401390.7188 - val_mean_squared_error: 401390.7188\n",
      "Epoch 5/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 236533904.0000 - mean_squared_error: 236533904.0000 - val_loss: 301999.0625 - val_mean_squared_error: 301999.0625\n",
      "Epoch 6/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 252212384.0000 - mean_squared_error: 252212384.0000 - val_loss: 1299.5874 - val_mean_squared_error: 1299.5874\n",
      "Epoch 7/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 161320752.0000 - mean_squared_error: 161320752.0000 - val_loss: 20698.4355 - val_mean_squared_error: 20698.4355\n",
      "Epoch 8/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 99677496.0000 - mean_squared_error: 99677496.0000 - val_loss: 2968.9275 - val_mean_squared_error: 2968.9275\n",
      "Epoch 9/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 67501344.0000 - mean_squared_error: 67501344.0000 - val_loss: 1746.6913 - val_mean_squared_error: 1746.6913\n",
      "Epoch 10/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 112582360.0000 - mean_squared_error: 112582360.0000 - val_loss: 1099.2631 - val_mean_squared_error: 1099.2631\n",
      "Epoch 11/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 136514192.0000 - mean_squared_error: 136514192.0000 - val_loss: 3654.1948 - val_mean_squared_error: 3654.1948\n",
      "Epoch 12/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 121174144.0000 - mean_squared_error: 121174144.0000 - val_loss: 1431.8890 - val_mean_squared_error: 1431.8890\n",
      "Epoch 13/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 99207408.0000 - mean_squared_error: 99207408.0000 - val_loss: 852.0222 - val_mean_squared_error: 852.0222\n",
      "Epoch 14/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 36928936.0000 - mean_squared_error: 36928936.0000 - val_loss: 1071.7396 - val_mean_squared_error: 1071.7396\n",
      "Epoch 15/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 32967138.0000 - mean_squared_error: 32967138.0000 - val_loss: 1206.1506 - val_mean_squared_error: 1206.1506\n",
      "Epoch 16/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 38870100.0000 - mean_squared_error: 38870100.0000 - val_loss: 1572.0753 - val_mean_squared_error: 1572.0753\n",
      "Epoch 17/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 66599452.0000 - mean_squared_error: 66599452.0000 - val_loss: 671.1353 - val_mean_squared_error: 671.1353\n",
      "Epoch 18/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 57037368.0000 - mean_squared_error: 57037368.0000 - val_loss: 902.5147 - val_mean_squared_error: 902.5147\n",
      "Epoch 19/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 26590024.0000 - mean_squared_error: 26590024.0000 - val_loss: 1079.4552 - val_mean_squared_error: 1079.4552\n",
      "Epoch 20/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 6567310.5000 - mean_squared_error: 6567310.5000 - val_loss: 543.8472 - val_mean_squared_error: 543.8472\n",
      "Epoch 21/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 5540508.5000 - mean_squared_error: 5540508.5000 - val_loss: 52155.8164 - val_mean_squared_error: 52155.8164\n",
      "Epoch 22/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 13079441.0000 - mean_squared_error: 13079441.0000 - val_loss: 589.4204 - val_mean_squared_error: 589.4204\n",
      "Epoch 23/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 29813784.0000 - mean_squared_error: 29813784.0000 - val_loss: 1170.6633 - val_mean_squared_error: 1170.6633\n",
      "Epoch 24/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 24115626.0000 - mean_squared_error: 24115626.0000 - val_loss: 29457.6914 - val_mean_squared_error: 29457.6914\n",
      "Epoch 25/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 11129422.0000 - mean_squared_error: 11129422.0000 - val_loss: 25518.4199 - val_mean_squared_error: 25518.4199\n",
      "Epoch 26/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 10555872.0000 - mean_squared_error: 10555872.0000 - val_loss: 7426.5215 - val_mean_squared_error: 7426.5215\n",
      "Epoch 27/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 8260402.0000 - mean_squared_error: 8260402.0000 - val_loss: 1645.7985 - val_mean_squared_error: 1645.7985\n",
      "Epoch 28/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 5007185.0000 - mean_squared_error: 5007185.0000 - val_loss: 2040.6498 - val_mean_squared_error: 2040.6498\n",
      "Epoch 29/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 4286099.0000 - mean_squared_error: 4286099.0000 - val_loss: 2653.2405 - val_mean_squared_error: 2653.2405\n",
      "Epoch 30/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 5776393.5000 - mean_squared_error: 5776393.5000 - val_loss: 10591.2744 - val_mean_squared_error: 10591.2744\n",
      "Epoch 31/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 7797710.5000 - mean_squared_error: 7797710.5000 - val_loss: 2690.3950 - val_mean_squared_error: 2690.3950\n",
      "Epoch 32/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 3988698.5000 - mean_squared_error: 3988698.5000 - val_loss: 1156.2076 - val_mean_squared_error: 1156.2076\n",
      "Epoch 33/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 4236556.0000 - mean_squared_error: 4236556.0000 - val_loss: 4667.6621 - val_mean_squared_error: 4667.6621\n",
      "Epoch 34/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 2321792.0000 - mean_squared_error: 2321792.0000 - val_loss: 1126.1122 - val_mean_squared_error: 1126.1122\n",
      "Epoch 35/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 1119870.5000 - mean_squared_error: 1119870.5000 - val_loss: 8977.2314 - val_mean_squared_error: 8977.2314\n",
      "Epoch 36/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 1891546.1250 - mean_squared_error: 1891546.1250 - val_loss: 5388.5278 - val_mean_squared_error: 5388.5278\n",
      "Epoch 37/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 5144778.5000 - mean_squared_error: 5144778.5000 - val_loss: 924.3781 - val_mean_squared_error: 924.3781\n",
      "Epoch 38/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 1905832.1250 - mean_squared_error: 1905832.1250 - val_loss: 42959.0781 - val_mean_squared_error: 42959.0781\n",
      "Epoch 39/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 489249.9688 - mean_squared_error: 489249.9688 - val_loss: 1271.7512 - val_mean_squared_error: 1271.7512\n",
      "Epoch 40/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 378364.1250 - mean_squared_error: 378364.1250 - val_loss: 714.9517 - val_mean_squared_error: 714.9517\n",
      "Epoch 41/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 399845.4062 - mean_squared_error: 399845.4062 - val_loss: 588.2783 - val_mean_squared_error: 588.2783\n",
      "Epoch 42/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 670289.2500 - mean_squared_error: 670289.2500 - val_loss: 1569.6394 - val_mean_squared_error: 1569.6394\n",
      "Epoch 43/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 646912.5000 - mean_squared_error: 646912.5000 - val_loss: 923.9918 - val_mean_squared_error: 923.9918\n",
      "Epoch 44/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 206273.6094 - mean_squared_error: 206273.6094 - val_loss: 1383.5536 - val_mean_squared_error: 1383.5536\n",
      "Epoch 45/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 11516.4639 - mean_squared_error: 11516.4639 - val_loss: 1422.1074 - val_mean_squared_error: 1422.1074\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587/587 [==============================] - 2s 3ms/step - loss: 5266.4082 - mean_squared_error: 5266.4082 - val_loss: 8030.2490 - val_mean_squared_error: 8030.2490\n",
      "Epoch 47/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 2741.6882 - mean_squared_error: 2741.6882 - val_loss: 2585.8518 - val_mean_squared_error: 2585.8518\n",
      "Epoch 48/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 3823.6326 - mean_squared_error: 3823.6326 - val_loss: 1658.5846 - val_mean_squared_error: 1658.5846\n",
      "Epoch 49/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 13139.7246 - mean_squared_error: 13139.7246 - val_loss: 2808.4622 - val_mean_squared_error: 2808.4622\n",
      "Epoch 50/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 98594.1719 - mean_squared_error: 98594.1719 - val_loss: 1074.3588 - val_mean_squared_error: 1074.3588\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 1074.3588 - mean_squared_error: 1074.3588\n",
      "Test mean squared error: 1074.3587646484375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = data.sample(frac=0.8, random_state=0)\n",
    "val_data = data.drop(train_data.index)\n",
    "\n",
    "# Preprocess the data\n",
    "train_labels = train_data.pop('blood_pressure')\n",
    "val_labels = val_data.pop('blood_pressure')\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(len(train_data.columns),)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels, epochs=50,\n",
    "                    validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_mse = model.evaluate(val_data, val_labels)\n",
    "\n",
    "print('Test mean squared error:', test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc288828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "587/587 [==============================] - 2s 2ms/step - loss: 387.6788 - accuracy: 0.6147 - val_loss: 143.7414 - val_accuracy: 0.7501\n",
      "Epoch 2/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 172.4952 - accuracy: 0.6222 - val_loss: 384.8857 - val_accuracy: 0.2501\n",
      "Epoch 3/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 204.5963 - accuracy: 0.6282 - val_loss: 631.7152 - val_accuracy: 0.7501\n",
      "Epoch 4/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 183.0227 - accuracy: 0.6261 - val_loss: 50.4061 - val_accuracy: 0.7499\n",
      "Epoch 5/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 166.3347 - accuracy: 0.6263 - val_loss: 140.3626 - val_accuracy: 0.7501\n",
      "Epoch 6/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 116.3094 - accuracy: 0.6253 - val_loss: 197.4374 - val_accuracy: 0.7501\n",
      "Epoch 7/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 111.5079 - accuracy: 0.6337 - val_loss: 158.3408 - val_accuracy: 0.7501\n",
      "Epoch 8/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 104.8643 - accuracy: 0.6296 - val_loss: 138.8887 - val_accuracy: 0.2529\n",
      "Epoch 9/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 83.3534 - accuracy: 0.6382 - val_loss: 147.1703 - val_accuracy: 0.2565\n",
      "Epoch 10/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 86.0513 - accuracy: 0.6336 - val_loss: 230.0884 - val_accuracy: 0.7501\n",
      "Epoch 11/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 91.8991 - accuracy: 0.6358 - val_loss: 35.0552 - val_accuracy: 0.7501\n",
      "Epoch 12/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 75.6312 - accuracy: 0.6354 - val_loss: 56.0924 - val_accuracy: 0.7501\n",
      "Epoch 13/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 60.2109 - accuracy: 0.6391 - val_loss: 113.8780 - val_accuracy: 0.7501\n",
      "Epoch 14/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 47.5419 - accuracy: 0.6360 - val_loss: 17.1626 - val_accuracy: 0.7516\n",
      "Epoch 15/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 40.4739 - accuracy: 0.6363 - val_loss: 13.2056 - val_accuracy: 0.7529\n",
      "Epoch 16/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 30.4746 - accuracy: 0.6416 - val_loss: 7.3220 - val_accuracy: 0.6253\n",
      "Epoch 17/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 30.2385 - accuracy: 0.6465 - val_loss: 31.6858 - val_accuracy: 0.7501\n",
      "Epoch 18/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 31.4623 - accuracy: 0.6553 - val_loss: 2.9284 - val_accuracy: 0.6875\n",
      "Epoch 19/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 35.4962 - accuracy: 0.6461 - val_loss: 33.0757 - val_accuracy: 0.7501\n",
      "Epoch 20/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 19.1243 - accuracy: 0.6508 - val_loss: 12.1465 - val_accuracy: 0.3353\n",
      "Epoch 21/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 22.0905 - accuracy: 0.6586 - val_loss: 67.3538 - val_accuracy: 0.7501\n",
      "Epoch 22/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 18.1762 - accuracy: 0.6541 - val_loss: 1.2114 - val_accuracy: 0.7797\n",
      "Epoch 23/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 12.7072 - accuracy: 0.6622 - val_loss: 0.7441 - val_accuracy: 0.8130\n",
      "Epoch 24/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 8.5116 - accuracy: 0.6643 - val_loss: 4.6918 - val_accuracy: 0.7503\n",
      "Epoch 25/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 7.0842 - accuracy: 0.6650 - val_loss: 2.4898 - val_accuracy: 0.7162\n",
      "Epoch 26/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 5.6423 - accuracy: 0.6665 - val_loss: 1.5321 - val_accuracy: 0.7463\n",
      "Epoch 27/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 3.8775 - accuracy: 0.6807 - val_loss: 15.8523 - val_accuracy: 0.7501\n",
      "Epoch 28/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 2.4010 - accuracy: 0.6970 - val_loss: 0.4998 - val_accuracy: 0.8106\n",
      "Epoch 29/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 1.3871 - accuracy: 0.7057 - val_loss: 1.1564 - val_accuracy: 0.7499\n",
      "Epoch 30/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 1.1412 - accuracy: 0.7065 - val_loss: 0.4148 - val_accuracy: 0.8027\n",
      "Epoch 31/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.6682 - accuracy: 0.7310 - val_loss: 2.4679 - val_accuracy: 0.7501\n",
      "Epoch 32/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.6678 - accuracy: 0.7253 - val_loss: 0.4418 - val_accuracy: 0.8259\n",
      "Epoch 33/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7407 - val_loss: 0.4502 - val_accuracy: 0.8034\n",
      "Epoch 34/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5351 - accuracy: 0.7434 - val_loss: 0.5053 - val_accuracy: 0.7682\n",
      "Epoch 35/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5262 - accuracy: 0.7418 - val_loss: 0.5341 - val_accuracy: 0.7497\n",
      "Epoch 36/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7475 - val_loss: 0.5144 - val_accuracy: 0.7995\n",
      "Epoch 37/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7436 - val_loss: 0.5563 - val_accuracy: 0.7520\n",
      "Epoch 38/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.5623 - accuracy: 0.7411 - val_loss: 0.5975 - val_accuracy: 0.7501\n",
      "Epoch 39/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5576 - accuracy: 0.7413 - val_loss: 0.7078 - val_accuracy: 0.2889\n",
      "Epoch 40/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.5841 - accuracy: 0.7379 - val_loss: 0.5877 - val_accuracy: 0.7501\n",
      "Epoch 41/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.6096 - accuracy: 0.7464 - val_loss: 0.5924 - val_accuracy: 0.7501\n",
      "Epoch 42/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5793 - accuracy: 0.7464 - val_loss: 0.5675 - val_accuracy: 0.7501\n",
      "Epoch 43/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7464 - val_loss: 0.5631 - val_accuracy: 0.7501\n",
      "Epoch 44/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5623 - val_accuracy: 0.7501\n",
      "Epoch 45/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5622 - val_accuracy: 0.7501\n",
      "Epoch 46/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5622 - val_accuracy: 0.7501\n",
      "Epoch 47/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5622 - val_accuracy: 0.7501\n",
      "Epoch 48/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5622 - val_accuracy: 0.7501\n",
      "Epoch 49/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5622 - val_accuracy: 0.7501\n",
      "Epoch 50/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5622 - val_accuracy: 0.7501\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7501\n",
      "Test accuracy: 0.7501065135002136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = data.sample(frac=0.8, random_state=0)\n",
    "val_data = data.drop(train_data.index)\n",
    "\n",
    "# Preprocess the data\n",
    "train_labels = train_data.pop('Label')\n",
    "val_labels = val_data.pop('Label')\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(7,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels, epochs=50,\n",
    "                    validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(val_data, val_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bb0faaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "587/587 [==============================] - 2s 1ms/step - loss: 0.2230 - accuracy: 0.9259\n",
      "Epoch 2/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 0.1044 - accuracy: 0.9605\n",
      "Epoch 3/50\n",
      "587/587 [==============================] - 1s 1ms/step - loss: 0.0628 - accuracy: 0.9779\n",
      "Epoch 4/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0504 - accuracy: 0.9815\n",
      "Epoch 5/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0418 - accuracy: 0.9843\n",
      "Epoch 6/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0358 - accuracy: 0.9874\n",
      "Epoch 7/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0314 - accuracy: 0.9885\n",
      "Epoch 8/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0282 - accuracy: 0.9893\n",
      "Epoch 9/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9908\n",
      "Epoch 10/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9917\n",
      "Epoch 11/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9920\n",
      "Epoch 12/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9927\n",
      "Epoch 13/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 14/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9940\n",
      "Epoch 15/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0174 - accuracy: 0.9938\n",
      "Epoch 16/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0156 - accuracy: 0.9950\n",
      "Epoch 17/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0145 - accuracy: 0.9949\n",
      "Epoch 18/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0141 - accuracy: 0.9952\n",
      "Epoch 19/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0138 - accuracy: 0.9952\n",
      "Epoch 20/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9960\n",
      "Epoch 21/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9957\n",
      "Epoch 22/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 23/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0101 - accuracy: 0.9964\n",
      "Epoch 24/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0095 - accuracy: 0.9970\n",
      "Epoch 25/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 26/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0088 - accuracy: 0.9974\n",
      "Epoch 27/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9968\n",
      "Epoch 28/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9968\n",
      "Epoch 29/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 30/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 31/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 32/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0069 - accuracy: 0.9975\n",
      "Epoch 33/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 34/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 35/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 36/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 37/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 38/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 39/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 40/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 41/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 42/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 43/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 44/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 45/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 46/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 47/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9981\n",
      "Epoch 48/50\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 49/50\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 50/50\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Accuracy: 100.00%\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "[[0.00602981]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Separate the features and label\n",
    "X = data.iloc[:, 2:-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale and normalize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Define the MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the MLP model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluate the MLP model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: %.2f%%' % (score[1] * 100))\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = [[70, 120, 98, 18, 36.5], [80, 130, 95, 20, 36.8]]\n",
    "new_data_scaled = sc.transform(new_data)\n",
    "predictions = model.predict(new_data_scaled)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "726556b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "470/470 [==============================] - 2s 2ms/step - loss: 0.2325 - accuracy: 0.9256 - val_loss: 0.1633 - val_accuracy: 0.9462\n",
      "Epoch 2/50\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 0.1294 - accuracy: 0.9507 - val_loss: 0.1033 - val_accuracy: 0.9627\n",
      "Epoch 3/50\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 0.0819 - accuracy: 0.9706 - val_loss: 0.0717 - val_accuracy: 0.9795\n",
      "Epoch 4/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 0.0585 - val_accuracy: 0.9798\n",
      "Epoch 5/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0500 - accuracy: 0.9810 - val_loss: 0.0484 - val_accuracy: 0.9800\n",
      "Epoch 6/50\n",
      "470/470 [==============================] - 2s 4ms/step - loss: 0.0442 - accuracy: 0.9836 - val_loss: 0.0414 - val_accuracy: 0.9830\n",
      "Epoch 7/50\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 0.0378 - accuracy: 0.9859 - val_loss: 0.0383 - val_accuracy: 0.9814\n",
      "Epoch 8/50\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9875 - val_loss: 0.0335 - val_accuracy: 0.9885\n",
      "Epoch 9/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.0318 - val_accuracy: 0.9912\n",
      "Epoch 10/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9897 - val_loss: 0.0295 - val_accuracy: 0.9891\n",
      "Epoch 11/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 0.0257 - val_accuracy: 0.9888\n",
      "Epoch 12/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9911 - val_loss: 0.0244 - val_accuracy: 0.9915\n",
      "Epoch 13/50\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.0232 - val_accuracy: 0.9901\n",
      "Epoch 14/50\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9925 - val_loss: 0.0220 - val_accuracy: 0.9925\n",
      "Epoch 15/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0221 - val_accuracy: 0.9928\n",
      "Epoch 16/50\n",
      "470/470 [==============================] - 2s 4ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.0165 - val_accuracy: 0.9933\n",
      "Epoch 17/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.0168 - val_accuracy: 0.9933\n",
      "Epoch 18/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0164 - val_accuracy: 0.9933\n",
      "Epoch 19/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9944 - val_loss: 0.0154 - val_accuracy: 0.9933\n",
      "Epoch 20/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.0124 - val_accuracy: 0.9949\n",
      "Epoch 21/50\n",
      "470/470 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.0158 - val_accuracy: 0.9936\n",
      "Epoch 22/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0134 - val_accuracy: 0.9933\n",
      "Epoch 23/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0097 - val_accuracy: 0.9976\n",
      "Epoch 24/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0141 - val_accuracy: 0.9952\n",
      "Epoch 25/50\n",
      "470/470 [==============================] - 2s 4ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0107 - val_accuracy: 0.9963\n",
      "Epoch 26/50\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0148 - val_accuracy: 0.9949\n",
      "Epoch 27/50\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0120 - val_accuracy: 0.9960\n",
      "Epoch 28/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0075 - val_accuracy: 0.9973\n",
      "Epoch 29/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.0075 - val_accuracy: 0.9971\n",
      "Epoch 30/50\n",
      "470/470 [==============================] - 2s 4ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0105 - val_accuracy: 0.9944\n",
      "Epoch 31/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0058 - val_accuracy: 0.9973\n",
      "Epoch 32/50\n",
      "470/470 [==============================] - 2s 4ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 33/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0070 - val_accuracy: 0.9968\n",
      "Epoch 34/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0067 - val_accuracy: 0.9979\n",
      "Epoch 35/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0062 - val_accuracy: 0.9973\n",
      "Epoch 36/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "Epoch 37/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0084 - val_accuracy: 0.9963\n",
      "Epoch 38/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0052 - val_accuracy: 0.9976\n",
      "Epoch 39/50\n",
      "470/470 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 40/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0037 - val_accuracy: 0.9995\n",
      "Epoch 41/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0035 - val_accuracy: 0.9984\n",
      "Epoch 42/50\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0055 - val_accuracy: 0.9979\n",
      "Epoch 43/50\n",
      "470/470 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0068 - val_accuracy: 0.9971\n",
      "Epoch 44/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9984\n",
      "Epoch 45/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 46/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0028 - val_accuracy: 0.9997\n",
      "Epoch 47/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 48/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.0023 - val_accuracy: 0.9984\n",
      "Epoch 49/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 0.9989\n",
      "Epoch 50/50\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Testing accuracy: 99.96%\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation and testing datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the MLP model on the training dataset\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the MLP model on the testing dataset\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Testing accuracy: %.2f%%' % (score[1] * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cec6cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chido\\AppData\\Local\\Temp\\ipykernel_27072\\707345256.py:37: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, input_shape=X_train.shape[1:], verbose=0)\n",
      "C:\\Users\\chido\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best hyperparameters:  {'learning_rate': 0.01, 'num_hidden_layers': 2, 'num_hidden_units': 128}\n",
      "Accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Define a function that returns the Keras model\n",
    "def create_model(input_shape, num_hidden_layers=1, num_hidden_units=64, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_hidden_units, input_shape=input_shape, activation='relu'))\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(Dense(num_hidden_units, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Separate the features and label\n",
    "X = data.iloc[:, 2:-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale and normalize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Wrap the Keras model inside a scikit-learn estimator\n",
    "model = KerasClassifier(build_fn=create_model, input_shape=X_train.shape[1:], verbose=0)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'num_hidden_layers': [1, 2, 3],\n",
    "    'num_hidden_units': [32, 64, 128],\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Accuracy: %.2f%%\" % (grid_search.best_score_ * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7899400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chido\\OneDrive - Northumbria University - Production Azure AD\\Documents\\Project\\Phython work\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a22cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.72%\n",
      "Precision: 99.89%\n",
      "Recall: 99.74%\n",
      "F1 score: 99.82%\n",
      "AUC: 99.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chido\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Separate the features and label\n",
    "X = data.iloc[:, 2:-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale and normalize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Create an MLP classifier with default hyperparameters\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the testing data\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Compute the performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "print(\"Precision: %.2f%%\" % (precision * 100))\n",
    "print(\"Recall: %.2f%%\" % (recall * 100))\n",
    "print(\"F1 score: %.2f%%\" % (f1 * 100))\n",
    "print(\"AUC: %.2f%%\" % (auc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ae2f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.74%\n",
      "Precision: 99.80%\n",
      "Recall: 99.86%\n",
      "F1 score: 99.83%\n",
      "AUC: 99.63%\n",
      "Confusion Matrix:\n",
      " [[1170    7]\n",
      " [   5 3512]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chido\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Separate the features and label\n",
    "X = data.iloc[:, 2:-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale and normalize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Create an MLP classifier with default hyperparameters\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the testing data\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Compute the performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics and confusion matrix\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "print(\"Precision: %.2f%%\" % (precision * 100))\n",
    "print(\"Recall: %.2f%%\" % (recall * 100))\n",
    "print(\"F1 score: %.2f%%\" % (f1 * 100))\n",
    "print(\"AUC: %.2f%%\" % (auc * 100))\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7143ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chido\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.74%\n",
      "Precision: 99.89%\n",
      "Recall: 99.77%\n",
      "F1 score: 99.83%\n",
      "AUC: 99.72%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Separate the features and label\n",
    "X = data.iloc[:, 2:-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale and normalize the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Create an MLP classifier with default hyperparameters\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the testing data\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Compute the performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "print(\"Precision: %.2f%%\" % (precision * 100))\n",
    "print(\"Recall: %.2f%%\" % (recall * 100))\n",
    "print(\"F1 score: %.2f%%\" % (f1 * 100))\n",
    "print(\"AUC: %.2f%%\" % (auc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4630f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 0s 908us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chido\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted class probabilities to class labels\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a46de4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4694,) (4694, 5)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape, y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ecb4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "587/587 [==============================] - 2s 2ms/step - loss: 0.3466\n",
      "Epoch 2/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.1164\n",
      "Epoch 3/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0949\n",
      "Epoch 4/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0825\n",
      "Epoch 5/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0740\n",
      "Epoch 6/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0676\n",
      "Epoch 7/10\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.0619\n",
      "Epoch 8/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0570\n",
      "Epoch 9/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0518\n",
      "Epoch 10/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.0470\n",
      "147/147 [==============================] - 0s 2ms/step\n",
      "Mean Squared Error: 6392.249582774803\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "624700a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 0s 2ms/step\n",
      "Mean Absolute Error: 1.2980637743475465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# predict target values for test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate mean absolute error (mae)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81f8373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 0s 2ms/step\n",
      "R-Squared (R2) Score: -34023.44602198277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# predict target values for test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate r-squared (r2) score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R-Squared (R2) Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f4ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
