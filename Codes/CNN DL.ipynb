{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f7d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "587/587 [==============================] - 2s 2ms/step - loss: 0.8656 - accuracy: 0.5075 - val_loss: 0.7179 - val_accuracy: 0.5058\n",
      "Epoch 2/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 6.4723 - accuracy: 0.4988 - val_loss: 0.7603 - val_accuracy: 0.4951\n",
      "Epoch 3/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7124 - accuracy: 0.5020 - val_loss: 0.7386 - val_accuracy: 0.4928\n",
      "Epoch 4/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7157 - accuracy: 0.5012 - val_loss: 0.7966 - val_accuracy: 0.5070\n",
      "Epoch 5/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7203 - accuracy: 0.5019 - val_loss: 0.7205 - val_accuracy: 0.4913\n",
      "Epoch 6/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7105 - accuracy: 0.5016 - val_loss: 0.7540 - val_accuracy: 0.4942\n",
      "Epoch 7/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7124 - accuracy: 0.5059 - val_loss: 0.7160 - val_accuracy: 0.4896\n",
      "Epoch 8/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7148 - accuracy: 0.4990 - val_loss: 0.7098 - val_accuracy: 0.4940\n",
      "Epoch 9/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7054 - accuracy: 0.5009 - val_loss: 0.7746 - val_accuracy: 0.4936\n",
      "Epoch 10/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7090 - accuracy: 0.4962 - val_loss: 0.7611 - val_accuracy: 0.4936\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7611 - accuracy: 0.4936\n",
      "Accuracy: 0.49360886216163635\n",
      "147/147 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Reshape the data\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], 1, 1, X.shape[1])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(1,1,6)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_data, val_labels)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf07ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chido\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\preprocessing\\image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (18774, 1, 1, 6) (6 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "587/587 [==============================] - 18s 27ms/step - loss: 5.2555 - accuracy: 0.4963 - val_loss: 0.7021 - val_accuracy: 0.4957\n",
      "Epoch 2/10\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7158 - accuracy: 0.4965 - val_loss: 0.7361 - val_accuracy: 0.5072\n",
      "Epoch 3/10\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7401 - accuracy: 0.5029 - val_loss: 0.7139 - val_accuracy: 0.4934\n",
      "Epoch 4/10\n",
      "587/587 [==============================] - 15s 26ms/step - loss: 0.7109 - accuracy: 0.5029 - val_loss: 0.7216 - val_accuracy: 0.5066\n",
      "Epoch 5/10\n",
      "587/587 [==============================] - 17s 29ms/step - loss: 0.7083 - accuracy: 0.5058 - val_loss: 0.7007 - val_accuracy: 0.4949\n",
      "Epoch 6/10\n",
      "587/587 [==============================] - 17s 29ms/step - loss: 0.7063 - accuracy: 0.5018 - val_loss: 0.7028 - val_accuracy: 0.4938\n",
      "Epoch 7/10\n",
      "587/587 [==============================] - 17s 29ms/step - loss: 0.7057 - accuracy: 0.4970 - val_loss: 0.7306 - val_accuracy: 0.5066\n",
      "Epoch 8/10\n",
      "587/587 [==============================] - 17s 29ms/step - loss: 0.7068 - accuracy: 0.5006 - val_loss: 0.6996 - val_accuracy: 0.4947\n",
      "Epoch 9/10\n",
      "587/587 [==============================] - 18s 30ms/step - loss: 0.7041 - accuracy: 0.4976 - val_loss: 0.7512 - val_accuracy: 0.5055\n",
      "Epoch 10/10\n",
      "587/587 [==============================] - 18s 30ms/step - loss: 0.7051 - accuracy: 0.4969 - val_loss: 0.6961 - val_accuracy: 0.5072\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.5072\n",
      "Accuracy: 0.507243275642395\n",
      "147/147 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Reshape the data\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], 1, 1, X.shape[1])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Create generator for augmented data\n",
    "augmented_data = datagen.flow(train_data, train_labels, batch_size=32)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(1,1,6)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with augmented data\n",
    "model.fit(augmented_data, epochs=10, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_data, val_labels)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ede86c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "587/587 [==============================] - 5s 4ms/step - loss: 0.7861 - accuracy: 0.5024 - val_loss: 0.6975 - val_accuracy: 0.5040\n",
      "Epoch 2/10\n",
      "587/587 [==============================] - 2s 4ms/step - loss: 0.7433 - accuracy: 0.5030 - val_loss: 0.7095 - val_accuracy: 0.5177\n",
      "Epoch 3/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7151 - accuracy: 0.4942 - val_loss: 0.7189 - val_accuracy: 0.4806\n",
      "Epoch 4/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7385 - accuracy: 0.4967 - val_loss: 0.7130 - val_accuracy: 0.4851\n",
      "Epoch 5/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7079 - accuracy: 0.4948 - val_loss: 0.6959 - val_accuracy: 0.5196\n",
      "Epoch 6/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7088 - accuracy: 0.5032 - val_loss: 0.7031 - val_accuracy: 0.5194\n",
      "Epoch 7/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7027 - accuracy: 0.4973 - val_loss: 0.6946 - val_accuracy: 0.4781\n",
      "Epoch 8/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7005 - accuracy: 0.4913 - val_loss: 0.6960 - val_accuracy: 0.4808\n",
      "Epoch 9/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7116 - accuracy: 0.5036 - val_loss: 0.6980 - val_accuracy: 0.4830\n",
      "Epoch 10/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.7036 - accuracy: 0.4958 - val_loss: 0.7043 - val_accuracy: 0.4825\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.4825\n",
      "Accuracy: 0.4825308918952942\n",
      "147/147 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Reshape the data\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X.shape[1], 1)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_data, val_labels)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16cfb5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 7s 0us/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m, shear_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m val_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m val_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\preprocessing\\image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m     \u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;124;03m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1649\u001b[0m         directory,\n\u001b[0;32m   1650\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1651\u001b[0m         target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[0;32m   1652\u001b[0m         color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[0;32m   1653\u001b[0m         keep_aspect_ratio\u001b[38;5;241m=\u001b[39mkeep_aspect_ratio,\n\u001b[0;32m   1654\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m   1655\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[0;32m   1656\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[0;32m   1657\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1658\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   1659\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m   1660\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m   1661\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m   1662\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m   1663\u001b[0m         follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m   1664\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m   1665\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   1666\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1667\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'train'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the input image size\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Load the VGG16 model without the top layer\n",
    "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Freeze the layers in the pre-trained model\n",
    "for layer in vgg16_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build a new model on top of the pre-trained model\n",
    "model = Sequential()\n",
    "model.add(vgg16_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set the training and validation data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train', target_size=(IMG_SIZE, IMG_SIZE), batch_size=32, class_mode='binary')\n",
    "val_generator = val_datagen.flow_from_directory('val', target_size=(IMG_SIZE, IMG_SIZE), batch_size=32, class_mode='binary')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=val_generator)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d55880c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49105240732850447\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "lr_model = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred = lr_model.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy of the model on the validation data\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d05276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Check if 'target' column is present\n",
    "if 'target' not in data.columns:\n",
    "    # Add the target column to the DataFrame\n",
    "    data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d442ea5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 140808 into shape (23468,1,1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Reshape the data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)\n\u001b[1;32m----> 3\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and validation sets\u001b[39;00m\n\u001b[0;32m      6\u001b[0m train_data, val_data, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 140808 into shape (23468,1,1,1)"
     ]
    }
   ],
   "source": [
    "# Reshape the data\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], 1, 1, X.shape[1])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(1,1,6)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_data, val_labels)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ec5942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id  icustay_id  heart_rate  blood_pressure  oxygen_saturation  \\\n",
      "0       94297    200697.0        93.0            94.0               98.0   \n",
      "1       94229    219381.0        97.0            96.0               98.0   \n",
      "2       94195    276193.0        82.0            96.0               97.0   \n",
      "3       94256    241577.0        98.0           196.0               96.0   \n",
      "4       93996    236789.0        98.0            92.0               99.0   \n",
      "\n",
      "   respiratory_rate  temperature  Label  target  \n",
      "0              39.0         36.0      1       0  \n",
      "1              16.0         36.5      0       1  \n",
      "2              25.0         36.3      1       1  \n",
      "3              16.0         36.5      1       1  \n",
      "4              28.0         37.2      1       1  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 1, 1, 6] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 42\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Define the data augmentation generator\u001b[39;00m\n\u001b[0;32m     36\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     37\u001b[0m                              width_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     38\u001b[0m                              height_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     39\u001b[0m                              zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     40\u001b[0m                              horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     43\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])),\n\u001b[0;32m     44\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     45\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     46\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     47\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     48\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     49\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     50\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     51\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m ])\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m     56\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     57\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[0;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    349\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters]\n\u001b[0;32m    350\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :])\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 1, 1, 6] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Print the dataframe to verify that the target column has been added\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape the data\n",
    "X = X.reshape(X.shape[0], 1, 1, X.shape[1])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the data augmentation generator\n",
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.1,\n",
    "                             horizontal_flip=True)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(1,1,X.shape[3])),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model using data augmentation\n",
    "history = model.fit(datagen.flow(train_data, train_labels, batch_size=32),\n",
    "                    steps_per_epoch=len(train_data) / 32,\n",
    "                    epochs=50,\n",
    "                    validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_data, val_labels)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f037060d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"max_pooling2d_3\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_3/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,32].\n\nCall arguments received by layer \"max_pooling2d_3\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and validation sets\u001b[39;00m\n\u001b[0;32m     24\u001b[0m train_data, val_data, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     27\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m)),\n\u001b[0;32m     28\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     29\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     30\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     31\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     32\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     33\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m ])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1973\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1970\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1972\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1973\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[0;32m   1977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_3\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_3/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,32].\n\nCall arguments received by layer \"max_pooling2d_3\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Reshape the data\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], 1, 1, X.shape[1])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(1,1,6)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_data, val_labels)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72c1b144",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d_5. Consider increasing the input size. Received input shape [None, 1, 1, 6] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and validation sets\u001b[39;00m\n\u001b[0;32m     24\u001b[0m train_data, val_data, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     27\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])),\n\u001b[0;32m     28\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     29\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     30\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     31\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m     32\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m ])\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[0;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    349\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters]\n\u001b[0;32m    350\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :])\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_5. Consider increasing the input size. Received input shape [None, 1, 1, 6] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Reshape the data\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], 1, 1, X.shape[1])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (1, 3), activation='relu', input_shape=(1, 1, X.shape[3])),\n",
    "    tf.keras.layers.MaxPooling2D((1, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_data, val_labels)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97a100b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d_6. Consider increasing the input size. Received input shape [None, 1, 1, 6] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m train_data, val_data, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Create the model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     28\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])),\n\u001b[0;32m     29\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     30\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     31\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     32\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     33\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     34\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m ])\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[0;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    349\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters]\n\u001b[0;32m    350\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :])\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_6. Consider increasing the input size. Received input shape [None, 1, 1, 6] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Reshape the data\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], 1, 1, X.shape[1])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(1, 1, X.shape[3])),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_data, val_labels)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(val_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffa8c32d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 131418 into shape (18774,128,128,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m img_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[0;32m     17\u001b[0m img_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m---> 18\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mreshape(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], img_height, img_width, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], img_height, img_width, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 131418 into shape (18774,128,128,1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "X = data.drop('Label', axis=1).values\n",
    "y = data['Label'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data into images\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "X_train = X_train.reshape(X_train.shape[0], img_height, img_width, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_height, img_width, 1)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_height, img_width, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b5aa479",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 117340 into shape (1,6,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Reshape the data for CNN model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Split data into train and test sets\u001b[39;00m\n\u001b[0;32m     22\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 117340 into shape (1,6,1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(['Label'], axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Reshape the data for CNN model\n",
    "X = X.to_numpy().reshape(-1, 1, 6, 1)\n",
    "\n",
    "reshaped_data = np.reshape(data, (19557, 6, 1))\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(1, 2), activation='relu', input_shape=(1, 6, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(1, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(1, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea9a18ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d_9. Consider increasing the input size. Received input shape [None, 1, 1, 32] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]))\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m---> 29\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[0;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    349\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters]\n\u001b[0;32m    350\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :])\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_9. Consider increasing the input size. Received input shape [None, 1, 1, 32] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "X = data.drop(['subject_id', 'icustay_id', 'Label'], axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for use in CNN\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1], 1))\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (1, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(MaxPooling2D((1, 2)))\n",
    "model.add(Conv2D(64, (1, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((1, 2)))\n",
    "model.add(Conv2D(128, (1, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((1, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27df5f91",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"max_pooling2d_11\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_11/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 1, 2, 1], padding=\"VALID\", strides=[1, 1, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n\nCall arguments received by layer \"max_pooling2d_11\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(X_test, (X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     25\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     26\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     27\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     28\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     29\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     30\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     31\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     32\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     33\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m ])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1973\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1970\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1972\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1973\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[0;32m   1977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_11\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_11/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 1, 2, 1], padding=\"VALID\", strides=[1, 1, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n\nCall arguments received by layer \"max_pooling2d_11\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Drop subject_id and icustay_id\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Split into features and target\n",
    "X = data.drop('Label', axis=1).values\n",
    "y = data['Label'].values\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data to fit the input shape of the model\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1], 1))\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (1, 3), padding='same', activation='relu', input_shape=(1, X_train.shape[2], 1)),\n",
    "    tf.keras.layers.MaxPooling2D((1, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (1, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((1, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (1, 3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((1, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08cdfa6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d_13. Consider increasing the input size. Received input shape [None, 5, 1, 1] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(X_test, (X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     20\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     21\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     22\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     23\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     24\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     25\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     26\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     27\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     28\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     29\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     30\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     31\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     32\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m ])\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[0;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    349\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters]\n\u001b[0;32m    350\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :])\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_13. Consider increasing the input size. Received input shape [None, 5, 1, 1] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "X = data.drop(['subject_id', 'icustay_id', 'Label'], axis=1).values\n",
    "y = data['Label'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for the CNN model\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1, 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1, 1))\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(1, 3), activation='relu', input_shape=(X_train.shape[1], 1, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(1, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(1, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(1, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f27f75f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"max_pooling2d_15\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_15/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,5,1,32].\n\nCall arguments received by layer \"max_pooling2d_15\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 5, 1, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m y_test \u001b[38;5;241m=\u001b[39m to_categorical(y_test)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     28\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])),\n\u001b[0;32m     29\u001b[0m     MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     30\u001b[0m     Dropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     31\u001b[0m     Flatten(),\n\u001b[0;32m     32\u001b[0m     Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     33\u001b[0m     Dropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     34\u001b[0m     Dense(\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m ])\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1973\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1970\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1972\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1973\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[0;32m   1977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_15\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_15/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,5,1,32].\n\nCall arguments received by layer \"max_pooling2d_15\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 5, 1, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(['subject_id', 'icustay_id', 'Label'], axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for the CNN model\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1, 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1, 1)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (1, 1), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07ff48f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2d_17\" (type Conv2D).\n\nNegative dimension size caused by subtracting 6 from 5 for '{{node conv2d_17/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_17/Conv2D/ReadVariableOp)' with input shapes: [?,5,1,1], [6,1,1,32].\n\nCall arguments received by layer \"conv2d_17\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 5, 1, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m y_test \u001b[38;5;241m=\u001b[39m to_categorical(y_test)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     34\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m1\u001b[39m), input_shape\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     35\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     36\u001b[0m     Dropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     37\u001b[0m     Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     38\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     39\u001b[0m     Dropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     40\u001b[0m     Flatten(),\n\u001b[0;32m     41\u001b[0m     Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     42\u001b[0m     Dropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m     43\u001b[0m     Dense(\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     44\u001b[0m ])\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1973\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1970\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1972\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1973\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1975\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[0;32m   1977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_17\" (type Conv2D).\n\nNegative dimension size caused by subtracting 6 from 5 for '{{node conv2d_17/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_17/Conv2D/ReadVariableOp)' with input shapes: [?,5,1,1], [6,1,1,32].\n\nCall arguments received by layer \"conv2d_17\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 5, 1, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=['subject_id', 'icustay_id'], inplace=True)\n",
    "\n",
    "# Convert the categorical labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df.drop(columns=['Label']).values\n",
    "y = df['Label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the training and testing sets\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1, 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1, 1))\n",
    "\n",
    "# Convert the labels to categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (6, 1), input_shape=X_train.shape[1:], activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(64, (3, 1), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# CNN\n",
    "X_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn.add(MaxPooling1D(pool_size=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn.fit(X_train_cnn, y_train, epochs=10, batch_size=32)\n",
    "y_pred = cnn.predict(X_test_cnn)\n",
    "y_pred = y_pred.flatten() # reshape to 1D array\n",
    "cnn_acc = accuracy_score(y_test, np.round(y_pred))\n",
    "cnn_cm = confusion_matrix(y_test, np.round(y_pred))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "391e6d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chido\\miniconda3\\envs\\doodoo\\Lib\\site-packages\\keras\\preprocessing\\image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (18774, 1, 1, 6) (6 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587/587 [==============================] - 17s 27ms/step - loss: 0.8297 - accuracy: 0.4974 - val_loss: 0.7095 - val_accuracy: 0.4938\n",
      "Epoch 2/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 2.3457 - accuracy: 0.4960 - val_loss: 0.9388 - val_accuracy: 0.4972\n",
      "Epoch 3/50\n",
      "587/587 [==============================] - 17s 29ms/step - loss: 0.7892 - accuracy: 0.4974 - val_loss: 0.7041 - val_accuracy: 0.5009\n",
      "Epoch 4/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7554 - accuracy: 0.5043 - val_loss: 0.7261 - val_accuracy: 0.5102\n",
      "Epoch 5/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7478 - accuracy: 0.4989 - val_loss: 0.8128 - val_accuracy: 0.5089\n",
      "Epoch 6/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7332 - accuracy: 0.4969 - val_loss: 0.7051 - val_accuracy: 0.5045\n",
      "Epoch 7/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7753 - accuracy: 0.5018 - val_loss: 0.7015 - val_accuracy: 0.5089\n",
      "Epoch 8/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7369 - accuracy: 0.4953 - val_loss: 0.7185 - val_accuracy: 0.4934\n",
      "Epoch 9/50\n",
      "587/587 [==============================] - 17s 28ms/step - loss: 15.9363 - accuracy: 0.5015 - val_loss: 0.7938 - val_accuracy: 0.5104\n",
      "Epoch 10/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7716 - accuracy: 0.5012 - val_loss: 0.9096 - val_accuracy: 0.4913\n",
      "Epoch 11/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7814 - accuracy: 0.5022 - val_loss: 0.7113 - val_accuracy: 0.4906\n",
      "Epoch 12/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7593 - accuracy: 0.5008 - val_loss: 0.8875 - val_accuracy: 0.5092\n",
      "Epoch 13/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7507 - accuracy: 0.5021 - val_loss: 0.7075 - val_accuracy: 0.5075\n",
      "Epoch 14/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7477 - accuracy: 0.5025 - val_loss: 0.7641 - val_accuracy: 0.5096\n",
      "Epoch 15/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7422 - accuracy: 0.4992 - val_loss: 0.7101 - val_accuracy: 0.4921\n",
      "Epoch 16/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7664 - accuracy: 0.5008 - val_loss: 0.7037 - val_accuracy: 0.4904\n",
      "Epoch 17/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7480 - accuracy: 0.4988 - val_loss: 0.7905 - val_accuracy: 0.4915\n",
      "Epoch 18/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7506 - accuracy: 0.4957 - val_loss: 0.7509 - val_accuracy: 0.4915\n",
      "Epoch 19/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7299 - accuracy: 0.5110 - val_loss: 0.7551 - val_accuracy: 0.4923\n",
      "Epoch 20/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7472 - accuracy: 0.5001 - val_loss: 0.7002 - val_accuracy: 0.4881\n",
      "Epoch 21/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7507 - accuracy: 0.5043 - val_loss: 0.7511 - val_accuracy: 0.4949\n",
      "Epoch 22/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7482 - accuracy: 0.5057 - val_loss: 0.7099 - val_accuracy: 0.5081\n",
      "Epoch 23/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7350 - accuracy: 0.5005 - val_loss: 0.6950 - val_accuracy: 0.4977\n",
      "Epoch 24/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7308 - accuracy: 0.5001 - val_loss: 0.7105 - val_accuracy: 0.5070\n",
      "Epoch 25/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7299 - accuracy: 0.5050 - val_loss: 0.6959 - val_accuracy: 0.4957\n",
      "Epoch 26/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7287 - accuracy: 0.5026 - val_loss: 0.7013 - val_accuracy: 0.4896\n",
      "Epoch 27/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7394 - accuracy: 0.4974 - val_loss: 0.7342 - val_accuracy: 0.4898\n",
      "Epoch 28/50\n",
      "587/587 [==============================] - 12s 20ms/step - loss: 0.7261 - accuracy: 0.5023 - val_loss: 0.7555 - val_accuracy: 0.4919\n",
      "Epoch 29/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7277 - accuracy: 0.4983 - val_loss: 0.6982 - val_accuracy: 0.5002\n",
      "Epoch 30/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7358 - accuracy: 0.5062 - val_loss: 0.7153 - val_accuracy: 0.4921\n",
      "Epoch 31/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7225 - accuracy: 0.4953 - val_loss: 0.7153 - val_accuracy: 0.4911\n",
      "Epoch 32/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7262 - accuracy: 0.5084 - val_loss: 0.7096 - val_accuracy: 0.5068\n",
      "Epoch 33/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7208 - accuracy: 0.4964 - val_loss: 0.7001 - val_accuracy: 0.4947\n",
      "Epoch 34/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7244 - accuracy: 0.4926 - val_loss: 0.6967 - val_accuracy: 0.5109\n",
      "Epoch 35/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7268 - accuracy: 0.4993 - val_loss: 0.7382 - val_accuracy: 0.4921\n",
      "Epoch 36/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7193 - accuracy: 0.4948 - val_loss: 0.6962 - val_accuracy: 0.5104\n",
      "Epoch 37/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7093 - accuracy: 0.4997 - val_loss: 0.6943 - val_accuracy: 0.4968\n",
      "Epoch 38/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 7.3857 - accuracy: 0.4975 - val_loss: 0.7336 - val_accuracy: 0.4915\n",
      "Epoch 39/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7248 - accuracy: 0.5036 - val_loss: 0.7124 - val_accuracy: 0.5064\n",
      "Epoch 40/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7186 - accuracy: 0.5005 - val_loss: 0.7002 - val_accuracy: 0.5068\n",
      "Epoch 41/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7228 - accuracy: 0.4998 - val_loss: 0.6966 - val_accuracy: 0.4889\n",
      "Epoch 42/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7167 - accuracy: 0.5013 - val_loss: 0.7112 - val_accuracy: 0.4874\n",
      "Epoch 43/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7148 - accuracy: 0.4986 - val_loss: 0.6953 - val_accuracy: 0.5104\n",
      "Epoch 44/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7130 - accuracy: 0.4962 - val_loss: 0.6945 - val_accuracy: 0.5102\n",
      "Epoch 45/50\n",
      "587/587 [==============================] - 15s 26ms/step - loss: 0.7120 - accuracy: 0.5044 - val_loss: 0.7061 - val_accuracy: 0.4921\n",
      "Epoch 46/50\n",
      "587/587 [==============================] - 16s 28ms/step - loss: 0.7102 - accuracy: 0.4981 - val_loss: 0.6966 - val_accuracy: 0.5081\n",
      "Epoch 47/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7059 - accuracy: 0.5010 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
      "Epoch 48/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7064 - accuracy: 0.4998 - val_loss: 0.6941 - val_accuracy: 0.4951\n",
      "Epoch 49/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7039 - accuracy: 0.5055 - val_loss: 0.6967 - val_accuracy: 0.5087\n",
      "Epoch 50/50\n",
      "587/587 [==============================] - 16s 27ms/step - loss: 0.7045 - accuracy: 0.5001 - val_loss: 0.7034 - val_accuracy: 0.5087\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.5087\n",
      "Accuracy: 0.5087345838546753\n",
      "147/147 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data['target'] = np.random.randint(0, 2, size=data.shape[0])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Reshape the data\n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], 1, 1, X.shape[1])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Create generator for augmented data\n",
    "augmented_data = datagen.flow(train_data, train_labels, batch_size=32)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(1,1,6)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with augmented data\n",
    "model.fit(augmented_data, epochs=50, validation_data=(val_data, val_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_data, val_labels)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ae94e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "587/587 [==============================] - 3s 3ms/step - loss: 2.1164 - accuracy: 0.7370\n",
      "Epoch 2/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.3132 - accuracy: 0.9047\n",
      "Epoch 3/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.2033 - accuracy: 0.9376\n",
      "Epoch 4/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.1619 - accuracy: 0.9522\n",
      "Epoch 5/10\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.1437 - accuracy: 0.9548\n",
      "Epoch 6/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9557\n",
      "Epoch 7/10\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.1296 - accuracy: 0.9558\n",
      "Epoch 8/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.1245 - accuracy: 0.9565\n",
      "Epoch 9/10\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.1261 - accuracy: 0.9542\n",
      "Epoch 10/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.1222 - accuracy: 0.9561\n",
      "147/147 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.9646357051555177\n",
      "Confusion Matrix:\n",
      " [[1153   17]\n",
      " [ 149 3375]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['Label'], axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Reshape the data for the CNN model\n",
    "X_train_cnn = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Define the CNN model\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn.add(MaxPooling1D(pool_size=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the CNN model\n",
    "cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the CNN model\n",
    "cnn.fit(X_train_cnn, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the CNN model\n",
    "y_pred = cnn.predict(X_test_cnn)\n",
    "y_pred = y_pred.flatten() # reshape to 1D array\n",
    "cnn_acc = accuracy_score(y_test, np.round(y_pred))\n",
    "cnn_cm = confusion_matrix(y_test, np.round(y_pred))\n",
    "\n",
    "# Print the accuracy and confusion matrix\n",
    "print('Accuracy:', cnn_acc)\n",
    "print('Confusion Matrix:\\n', cnn_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88736ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "587/587 [==============================] - 3s 3ms/step - loss: 1.0487 - accuracy: 0.7653\n",
      "Epoch 2/10\n",
      "587/587 [==============================] - 1s 2ms/step - loss: 0.2986 - accuracy: 0.8957\n",
      "Epoch 3/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.2718 - accuracy: 0.9164\n",
      "Epoch 4/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.2659 - accuracy: 0.9213\n",
      "Epoch 5/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.2650 - accuracy: 0.9239\n",
      "Epoch 6/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.2625 - accuracy: 0.9269\n",
      "Epoch 7/10\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.2623 - accuracy: 0.9273\n",
      "Epoch 8/10\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.2631 - accuracy: 0.9292\n",
      "Epoch 9/10\n",
      "587/587 [==============================] - 2s 3ms/step - loss: 0.2661 - accuracy: 0.9224\n",
      "Epoch 10/10\n",
      "587/587 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.9297\n",
      "147/147 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.9352364720920324\n",
      "Confusion Matrix:\n",
      " [[1144  109]\n",
      " [ 195 3246]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1253\n",
      "           1       0.97      0.94      0.96      3441\n",
      "\n",
      "    accuracy                           0.94      4694\n",
      "   macro avg       0.91      0.93      0.92      4694\n",
      "weighted avg       0.94      0.94      0.94      4694\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, cnn_cr)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Plot the confusion matrix\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m plot_confusion_matrix(cnn, X_test_cnn, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate the AUC value\n",
    "auc_value = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the AUC value\n",
    "print('AUC:', auc_value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Remove irrelevant features\n",
    "data = data.drop(['subject_id', 'icustay_id'], axis=1)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop(['Label'], axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Reshape the data for the CNN model\n",
    "X_train_cnn = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Define the CNN model\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn.add(MaxPooling1D(pool_size=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the CNN model\n",
    "cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the CNN model\n",
    "cnn.fit(X_train_cnn, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the CNN model\n",
    "y_pred = cnn.predict(X_test_cnn)\n",
    "y_pred = y_pred.flatten() # reshape to 1D array\n",
    "cnn_acc = accuracy_score(y_test, np.round(y_pred))\n",
    "cnn_cm = confusion_matrix(y_test, np.round(y_pred))\n",
    "cnn_cr = classification_report(y_test, np.round(y_pred))\n",
    "\n",
    "# Print the accuracy, confusion matrix, and classification report\n",
    "print('Accuracy:', cnn_acc)\n",
    "print('Confusion Matrix:\\n', cnn_cm)\n",
    "print('Classification Report:\\n', cnn_cr)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(cnn, X_test_cnn, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "931aa787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\chido\\miniconda3\\envs\\doodoo\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c451798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "sns.set(font_scale=1.4) # adjust the font size\n",
    "sns.heatmap(cnn_cm, annot=True, fmt='g', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efa042b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 23468\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('20thMarch_CVD.csv')\n",
    "\n",
    "# Get the size of the dataset\n",
    "dataset_size = data.shape[0]\n",
    "\n",
    "# Print the dataset size\n",
    "print(\"Dataset size:\", dataset_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee0a892",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the AUC value\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m auc_value \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_pred)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the AUC value\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC:\u001b[39m\u001b[38;5;124m'\u001b[39m, auc_value)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the AUC value\n",
    "auc_value = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the AUC value\n",
    "print('AUC:', auc_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8cf8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
